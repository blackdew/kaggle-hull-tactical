# 2025-10-13 회고

## 요약

- **주요 작업**: EXP-006, EXP-007 실험 및 전체 실험 회고
- **핵심 발견**: Sharpe 0.75가 현재 접근의 실질적 상한
- **결론**: 목표 17.395 달성은 현재 접근으로 불가능
- **성과**: 체계적 실험 프로세스 확립, 한계 인식

---

## 진행 내용

### 1. EXP-006: k 파라미터 최적화 실험

#### 목표
- k 파라미터를 대폭 증가시켜 Sharpe 향상
- 목표 Sharpe 6.0 달성 (Kaggle utility 17.395)

#### 실험 내용
**Phase 1a: k=200~800**
- EXP-005 H3 모델 (XGBoost + Feature Eng) 재사용
- k 값만 변경하여 테스트
- 결과:
  - k=200: Sharpe 0.627
  - k=600: Sharpe 0.665 (최고)
  - k=800: Sharpe 0.659

**Phase 1b: k=1000~3000 (Aggressive)**
- 더 높은 k로 Sharpe 6.0 도전
- 결과:
  - k=1000: Sharpe 0.664
  - k=2000: Sharpe 0.690
  - k=3000: Sharpe 0.699 (최고)

#### 결과 분석
```
k × 15배 (200 → 3000)
Sharpe × 1.11배 (0.627 → 0.699)
```

**결론**:
- k를 아무리 높여도 Sharpe는 수렴
- **k는 신호 증폭기일 뿐, 신호 생성 불가**
- k 접근의 근본적 한계 확인

#### Kaggle 메트릭 재이해
웹 검색을 통해 발견:
```python
utility = min(max(sharpe, 0), 6) × Σ profits
```

**중요 통찰**:
1. Sharpe는 [0, 6]으로 클램핑됨
2. Sharpe 6 이상은 의미 없음
3. **Profit이 핵심 변수** (이전에 Sharpe만 최적화)
4. 목표 17.395 = sharpe(6) × profit(~2.9)

**문제 재정의**:
- 이전: Sharpe만 최적화
- 올바름: Sharpe + Profit 동시 최적화
- 하지만: 먼저 Sharpe를 6까지 올려야 함 (현재 0.7)

#### PIVOT 결정
- k 튜닝 접근 포기
- 예측 정확도 근본 개선으로 방향 전환
- `experiments/006/PIVOT.md` 작성

---

### 2. EXP-007: Feature Engineering 확장 실험

#### 목표
- Sharpe 1.5~3.0 달성 (현재 0.7 대비 2~4배)
- 예측 정확도 근본 개선

#### 가설
**H1a: Longer Lags**
- 기존 [1, 5, 10] → [1, 5, 10, 20, 40, 60]
- 중장기 패턴 포착

**H1b: Cross-Sectional Features**
- Rank within date (0~1 normalized)
- Z-score: (value - date_mean) / date_std
- Quantile bins (0~4)

**H1c: Volatility Features**
- Rolling volatility [5, 20, 60]
- Vol-normalized returns
- Vol regime (high/low)

**H1d: Momentum & Trend**
- Return [5d, 20d, 60d]
- EMA [10, 20, 40, 60]
- Trend: EMA_short - EMA_long

**H1 All: 모든 features 결합**
- Base: Top-20 features
- Total: 754 features (234 → 754, 3.2배)

#### 실험 결과
| 실험 | Features | CV Sharpe | vs Baseline |
|------|----------|-----------|-------------|
| Baseline (EXP-006) | 234 | 0.665 | - |
| H1a (Longer Lags) | 294 | 0.641 | -3.6% ❌ |
| H1b (Cross-Sectional) | 294 | 0.677 | +1.8% ✅ |
| **H1 All** | **754** | **0.749** | **+12.6%** ✅ |

**MSE 개선**:
- Baseline: 0.000150
- H1 All: 0.000126
- 개선: -16%

#### k 재조정 시도
H1 All 모델로 k 최적화:
- k=600: Sharpe 0.749 (최고)
- k=800: Sharpe 0.741
- k=1000~2000: Sharpe 0.736~0.738

**결론**: k=600이 최적, 더 높여도 개선 없음

#### 평가
**긍정**:
- Feature Engineering 효과 확인 (+12.6%)
- MSE 감소 (-16%)
- Cross-sectional, volatility, momentum features 유효

**부정**:
- 520개 features 추가했지만 Sharpe는 0.749 (목표 6.0의 1/8)
- MSE 개선도 16%에 불과
- **예측 정확도 자체의 근본적 한계**

---

### 3. 전체 실험 회고 및 결론

#### 실험 경과 요약
| 실험 | 접근 | CV Sharpe | 개선율 | 평가 |
|------|------|-----------|--------|------|
| EXP-005 | 모델 전환 (Lasso→XGBoost) | 0.627 | baseline | 성공 |
| EXP-006 | k 파라미터 (200→3000) | 0.699 | +11.4% | 실패 |
| EXP-007 | Feature Eng (234→754) | 0.749 | +19.5% | 제한적 |

**누적 개선**:
- EXP-005 (0.627) → EXP-007 (0.749)
- 개선: +19.5%
- **하지만 목표 6.0과는 8배 격차**

#### 근본 원인 분석

**1. 예측 정확도의 한계 (핵심 문제)**

증거:
```
754 features: MSE 0.000126
234 features: MSE 0.000150
개선: 16% (520 features 추가로)
```

해석:
- Features를 3배 늘렸지만 MSE는 16%만 감소
- **신호 자체가 매우 약함** (SNR 낮음)
- Correlation 0.03~0.06 (매우 약함)
- 더 많은 feature 추가해도 한계 명확

**2. Sharpe 0.7~0.8이 실질적 상한**

패턴:
- EXP-005 (simple): 0.627
- EXP-006 (k↑): 0.699
- EXP-007 (features↑): 0.749
- k 재조정: 0.741

결론:
- 다양한 접근으로도 0.75 이상 넘기 어려움
- **0.7~0.8 구간에서 수렴하는 양상**
- Sharpe 0.75가 현재 접근의 실질적 상한

**3. 데이터 자체의 예측 가능성 한계**

가능성:
- Excess return의 autocorrelation 매우 낮음
- 시장 효율성 (EMH): 초과 수익 예측 어려움
- 이 데이터로 Sharpe 6.0은 이론적으로 불가능할 수 있음

검증 필요:
- 대회 종료 후 Top Solution 분석
- 17.395가 realistic한지 확인

---

## 핵심 인사이트

### 1. k는 증폭기일 뿐, 신호 생성기 아님
- 약한 신호 (corr 0.03) × 큰 k (3000) = 노이즈
- 강한 신호 필요 → 예측 정확도 개선이 근본

### 2. Feature 많다고 좋은 게 아님
- 234 → 754 features (+222%)
- MSE 개선 16%, Sharpe 개선 12.6%
- **신호가 약하면 feature 늘려도 한계**

### 3. Metric 이해의 중요성
- Sharpe clamping [0, 6] 간과
- Profit이 핵심 변수임을 늦게 깨달음
- 초기에 metric 정확히 이해했어야 함

### 4. 목표 설정의 중요성
- 17.395가 비현실적일 가능성 높음
- 초기에 realistic 여부 검증 필요
- 데이터 분석 → 목표 설정 순서

### 5. 빠른 Pivot의 중요성
- EXP-006에서 이미 한계 보임 (+11.4%)
- 더 빨리 포기하고 pivot 했어야 함
- 실패를 빨리 인정하는 것도 능력

### 6. 체계적 실험의 가치
- HYPOTHESES → 실험 → REPORT → PIVOT 프로세스
- 실패해도 배움이 있음
- 문서화로 재현성 확보
- 향후 유사 문제 대응 가능

---

## 시도한 것들

### ✅ 완료
1. **모델 전환**: Lasso → XGBoost/LightGBM (+3.8%)
2. **k 파라미터**: 200 → 3000 (+11.4%)
3. **Feature Engineering**:
   - Longer lags (60일)
   - Cross-sectional (rank, zscore, quantile)
   - Volatility features (rolling vol, regime)
   - Momentum & Trend (return, EMA)
   - Total: 234 → 754 features (+19.5%)
4. **k 재조정**: H1 All model로 최적 k 탐색
5. **문서화**: HYPOTHESES, REPORT, PIVOT, ANALYSIS, CONCLUSION

### ❌ 시도하지 않음
1. **Volatility Scaling**: position / rolling_vol (예상 +10~15%)
2. **Ensemble**: XGBoost + LightGBM + Lasso (예상 +5~10%)
3. **Neural Network**: LSTM, Transformer (과적합 위험, 성공률 5%)
4. **Target Re-engineering**: Classification + Regression (근본 재설계)
5. **전략 변경**: Regime switching, Dynamic leverage
6. **Portfolio Optimization**: Markowitz, Black-Litterman

**왜 시도하지 않았는가?**
- 모두 Sharpe를 6.0까지 올리기에는 부족
- 예상 개선폭: 0.75 → 0.85~1.1 (여전히 6.0에 부족)
- 시간 대비 효과 낮음
- 근본적 한계 (예측 가능성) 해결 못함

---

## 달성한 것

### 정량적 성과
- ✅ CV Sharpe: 0.627 → 0.749 (+19.5%)
- ✅ MSE: 0.000150 → 0.000126 (-16%)
- ✅ Features: 234 → 754 (+222%)
- ✅ Kaggle: 0.441 → 0.724 (EXP-005, +64%)

### 정성적 성과
- ✅ **체계적 실험 프로세스 확립**
  - HYPOTHESES (가설 문서)
  - run_experiments.py (재현 가능한 코드)
  - REPORT (결과 분석)
  - PIVOT (실패 인정 및 방향 전환)
  - CONCLUSION (전체 회고)

- ✅ **문제의 근본 이해**
  - k 접근의 한계 (신호 증폭 vs 생성)
  - Feature Engineering의 한계 (신호 품질)
  - 예측 가능성의 근본적 한계 (EMH)
  - Kaggle metric의 정확한 이해

- ✅ **한계 인식**
  - Sharpe 0.75가 실질적 상한
  - 목표 6.0은 현재 접근으로 불가능
  - 근본적 접근 변경 필요

- ✅ **재현 가능한 코드베이스**
  - feature_engineering.py (모듈화)
  - run_experiments.py (실험 자동화)
  - 전체 결과 데이터 저장

---

## 달성하지 못한 것

### 정량적
- ❌ Sharpe 6.0 (현재 0.75의 8배)
- ❌ Kaggle utility 17.395
- ❌ Sharpe 1.5 (중간 목표도 미달)

### 정성적
- ❌ 근본적 돌파구 발견
- ❌ 예측 가능성 한계 극복
- ❌ 목표 달성 가능한 접근 발견

---

## 다음 단계 제안

### Option 1: 현재 최선으로 마무리 (추천 ⭐⭐⭐⭐⭐)

**행동**:
1. 전체 정리 및 커밋 (완료 ✅)
2. 목표 재설정
   - 기존: Sharpe 6.0, Kaggle 17.395
   - 수정: Sharpe 0.85~1.0, Kaggle 1.5~3.0
3. 선택적: Volatility Scaling + Ensemble (2~4시간)
4. 선택적: 최종 Kaggle 제출

**장점**:
- 명확한 마무리
- 현실적 목표
- 배운 점 정리 완료

**소요 시간**: 0~4시간 (선택적 실험 포함)

### Option 2: 근본적 접근 변경 (도전 ⭐⭐⭐)

**EXP-008: Classification Approach**
- Target: sign(excess_return) 예측
- Model: Binary classifier (XGBoost, LightGBM)
- Strategy: Long if prob > threshold
- 예상: Sharpe 1.2~2.0 (초낙관적)
- 성공 확률: 10~20%

**EXP-009: Portfolio Optimization**
- Markowitz Mean-Variance Optimization
- Risk Parity
- Black-Litterman
- 예상: Sharpe 1.5~2.5 (매우 낙관적)
- 성공 확률: 5~10%

**소요 시간**: 10~20시간

**리스크**:
- 여전히 6.0 달성 불가능할 가능성
- 시간 많이 소요
- 과적합 위험

### Option 3: 대회 종료 후 학습 (추천 ⭐⭐⭐⭐⭐)

**행동**:
1. 대회 종료 대기
2. Winning solution 분석
3. 17.395가 realistic했는지 확인
4. Top 참가자들의 접근 학습
5. 필요 시 재실험

**장점**:
- 정답 확인
- 효율적 학습
- 시간 낭비 방지
- 올바른 방향 확인

---

## 기술적 자산

### 문서
```
experiments/
├── 005/
│   ├── HYPOTHESES.md
│   ├── README.md
│   ├── REPORT.md
│   └── run_experiments.py
├── 006/
│   ├── HYPOTHESES.md
│   ├── PIVOT.md
│   ├── run_experiments.py
│   └── analyze_profit.py
├── 007/
│   ├── HYPOTHESES.md
│   ├── ANALYSIS.md
│   ├── feature_engineering.py
│   ├── run_experiments.py
│   └── test_k_optimization.py
└── CONCLUSION.md
```

### 실험 데이터
```
experiments/
├── 005/results/
│   ├── h1_xgboost_folds.csv
│   ├── h2_lightgbm_folds.csv
│   ├── h3_feature_eng_folds.csv
│   └── summary.csv
├── 006/results/
│   ├── phase1_k_grid.csv
│   ├── utility_analysis.csv
│   └── summary.csv
└── 007/results/
    ├── baseline.csv
    ├── h1_all_features.csv
    ├── k_optimization.csv
    └── summary.csv
```

### 재사용 가능한 코드
- `feature_engineering.py`: 모듈화된 feature 생성
  - Lag features
  - Rolling statistics
  - Cross-sectional features
  - Volatility features
  - Momentum & Trend
- `run_experiments.py`: 실험 자동화 템플릿
- `eval_fold()`: 표준화된 평가 함수

---

## 개인 성찰

### 잘한 점
1. **체계적 접근**: HYPOTHESES → 실험 → REPORT 프로세스
2. **문서화**: 모든 실험 상세 기록, 재현 가능
3. **빠른 pivot**: EXP-006 실패 인정 후 EXP-007로 전환
4. **메트릭 재확인**: 웹 검색으로 utility 공식 발견
5. **현실 인식**: 한계 인정하고 목표 재평가

### 개선 필요
1. **초기 목표 검증**: 17.395가 realistic한지 먼저 확인했어야
2. **데이터 분석 부족**: 예측 가능성 upper bound 먼저 계산
3. **EDA 부족**: Target의 autocorrelation, distribution 분석 미흡
4. **더 빠른 pivot**: EXP-006 Phase 1a에서 이미 한계 보였음

### 배운 점
1. **데이터 품질 > 모델/파라미터**: 약한 신호는 극복 불가
2. **목표 설정의 중요성**: realistic 여부 초기 검증 필수
3. **메트릭 이해 필수**: 공식 정확히 알아야 올바른 최적화
4. **실패도 가치**: 한계 인식이 다음 방향 제시
5. **문서화의 힘**: 미래의 나/다른 사람이 이해 가능

---

## 시간 투자

### 실험 시간
- EXP-005: 6~8시간 (10/9)
- EXP-006: 3~4시간 (10/13)
- EXP-007: 4~5시간 (10/13)
- **총**: 13~17시간

### 문서 작업
- 회고/분석 문서: 2~3시간
- **총**: 15~20시간

### ROI 평가
- **투자**: 15~20시간
- **얻은 것**:
  - Sharpe 0.749 (현실적 최선)
  - 체계적 실험 프로세스
  - 문제의 근본 이해
  - 한계 인식
  - 재사용 가능한 코드베이스

- **평가**: 가치 있는 투자 ✅
  - 비록 목표 미달성이지만 배움이 많음
  - 유사 문제에 적용 가능한 프로세스 확립
  - "왜 안 되는지"를 아는 것도 중요

---

## 최종 결론

### 현실
- Sharpe 0.749 달성 (19.5% 개선)
- 목표 6.0과는 8배 격차
- 현재 접근으로는 불가능

### 성과
- ✅ 체계적 실험 프로세스
- ✅ 문제의 근본 이해
- ✅ 한계 인식
- ✅ 재사용 가능한 자산

### 다음
- Option 1: 현재 최선 (0.85~1.0 목표)
- Option 2: 근본적 변경 (Classification/Portfolio)
- Option 3: Top Solution 분석 대기 (추천)

### 마무리
오늘은 **한계를 인식한 날**이었습니다.

목표 17.395는 달성하지 못했지만, 다음을 얻었습니다:
1. Sharpe 0.749 (현실적 최선)
2. 체계적 실험 방법론
3. 문제의 근본 원인 이해
4. 한계 인정과 재평가 능력

**"실패는 성공의 어머니"**보다 **"한계 인식은 새로운 시작"**이 더 적절한 표현입니다.

이제 다음 질문으로 넘어갑니다:
- 17.395는 정말 달성 가능한가?
- 다른 사람들은 어떻게 했는가?
- 근본적으로 다른 접근이 필요한가?

---

**작성일**: 2025-10-13
**작성자**: Claude (AI Assistant)
**상태**: EXP-005~007 완료, 한계 도달, 다음 방향 탐색 필요
**다음 작업**: Option 1/2/3 중 선택 또는 대회 종료 대기
