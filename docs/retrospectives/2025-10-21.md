# 2025-10-21 회고

## 요약

- **주요 작업**: EXP-016 완전 재설계 및 제출 성공
- **핵심 발견**: InferenceServer 호환성이 핵심, Interaction Features 효과
- **결과**: Public Score **4.440** (Version 9의 0.724 대비 **6.1배** 향상)
- **성과**: 처음부터 재설계하는 결단, 제약 조건 이해, 최고 기록 달성

---

## 진행 내용

### 1. 문제 발견: InferenceServer 호환성

#### 초기 상황
- EXP-016 초기 버전: CV Sharpe 1.001 (3-fold), 0.781 (5-fold)
- Kaggle 제출: Version 10~13 모두 **ERROR**
- 원인 불명으로 여러 시도 반복

#### 근본 원인 분석
**문제**: Top 20 features에 lag/rolling features 포함
- `V13_lag1`, `M2_rolling_mean_10`, `S2_ema_60` 등
- 이러한 features는 여러 행의 데이터 필요

**Kaggle 제약**: InferenceServer는 **row-by-row** 예측
```python
# InferenceServer의 predict는 한 번에 1 row씩 호출
def predict(self, test_batch):  # test_batch = 1 row
    # lag/rolling features 계산 불가능!
```

**결론**: 기존 접근으로는 제출 자체가 불가능

---

### 2. 완전 재설계 결정

#### 방향 전환
사용자 피드백:
> "feature engineering으로 기존 모델 보다 더 좋은 새로운 피처를 추가해서 사용하면 안돼?"

> "016 실험 전체를 처음부터 다시 설계해서 진행해줘. 기존 내용은 모두 삭제하고,"

**핵심 통찰**:
- lag/rolling features 포기
- **1 row에서 계산 가능한 features만** 사용
- Interaction features로 성능 확보

#### 백업 및 재시작
```bash
# 기존 EXP-016을 백업
mv experiments/016 experiments/016_backup

# 완전히 새로 시작
mkdir experiments/016
```

---

### 3. 3단계 실험 설계 및 실행

#### Phase 1: 원본 Features 선택 (experiments/016/phase1_analyze_features.py)

**목표**: lag/rolling 없는 원본 features Top 20 선택

**방법**:
1. 94개 원본 features 필터링 (lag/rolling/ema 제외)
2. RandomForest importance 분석
3. Target correlation 분석
4. Combined ranking (importance + correlation)

**결과**:
```python
Top 20 features = [
    'M4', 'V13', 'V7', 'P8', 'S2', 'I2', 'E19', 'S5', 'P5', 'P7',
    'M2', 'V9', 'M3', 'P12', 'P10', 'V10', 'E12', 'P11', 'M12', 'S8'
]
```

**분포**:
- M (Market): 4개
- V (Volatility): 3개
- P (Price): 5개
- S (Sentiment): 3개
- I (Interest): 1개
- E (Economic): 2개
- Others: 2개

---

#### Phase 2: Interaction Features 생성 (experiments/016/phase2_feature_engineering.py)

**목표**: Top 20 features로 1-row 계산 가능한 interaction features 생성

**방법**:
```python
# 1. Multiplication (Top 10 조합)
for i, feat1 in enumerate(top_10):
    for feat2 in top_10[i+1:]:
        features[f'{feat1}*{feat2}'] = df[feat1] * df[feat2]
# 45개 생성

# 2. Division (Top 10 조합, epsilon 추가)
for i, feat1 in enumerate(top_10):
    for feat2 in top_10[i+1:]:
        features[f'{feat1}/{feat2}'] = df[feat1] / (df[feat2].abs() + 1e-8)
# 45개 생성

# 3. Polynomial (Top 5 제곱/세제곱)
for feat in top_5:
    features[f'{feat}²'] = df[feat] ** 2
    features[f'{feat}³'] = df[feat] ** 3
# 10개 생성
```

**생성 features**: 총 120개 (45 + 45 + 10 + 20 base)

**Feature Selection**:
- XGBoost로 importance 계산
- Top 30 features 선택

**성능 개선**:
```
Top 20 (base):            MSE = 0.000137
Top 30 (with interactions): MSE = 0.000132  (-3.6%)
```

**Top 10 Interaction Features**:
1. `P8*S2` (Price × Sentiment)
2. `M4*V7` (Market × Volatility)
3. `P8/P7` (Price ratio)
4. `V7*P7` (Volatility × Price)
5. `M4/S2` (Market / Sentiment)
6. `S2*S5` (Sentiment interaction)
7. `S5/P7` (Sentiment / Price)
8. `M4*P8` (Market × Price)
9. `M4²` (Market squared)
10. `V13²` (Volatility squared)

---

#### Phase 3: Sharpe Evaluation (experiments/016/phase3_sharpe_evaluation.py)

**목표**: 실제 Sharpe ratio 계산 및 최적 K 값 탐색

**방법**:
```python
def calculate_sharpe(y_pred, y_true, fwd_returns, risk_free, k=200.0):
    # 1. Excess return → Position
    positions = np.clip(1.0 + y_pred * k, 0.0, 2.0)

    # 2. Strategy returns
    strategy_returns = risk_free * (1.0 - positions) + fwd_returns * positions
    excess_returns = strategy_returns - risk_free

    # 3. Sharpe ratio (annualized)
    sharpe = (np.mean(excess_returns) / np.std(strategy_returns)) * np.sqrt(252)
    return sharpe

# K 값 테스트
K_values = [50, 100, 150, 200, 250, 300]
```

**K Parameter 최적화 결과**:
```
K=50:  Sharpe = 0.421 ± 0.280
K=100: Sharpe = 0.492 ± 0.321
K=150: Sharpe = 0.529 ± 0.345
K=200: Sharpe = 0.548 ± 0.358
K=250: Sharpe = 0.559 ± 0.362  ← Best!
K=300: Sharpe = 0.556 ± 0.364
```

**Best K=250**: Sharpe = **0.559** (5-fold CV)

**Model Hyperparameters**:
```python
XGBRegressor(
    n_estimators=150,
    max_depth=7,
    learning_rate=0.025,
    subsample=1.0,
    colsample_bytree=0.6,
    reg_lambda=0.5,
    random_state=42
)
```

---

### 4. InferenceServer 구현 (submissions/submission.py)

**핵심 설계**: Row-by-row 예측 가능한 구조

```python
class EXP016V2Server(InferenceServer):
    def __init__(self):
        self.top_30_features = [...]  # Top 30 interaction features
        self.top_20_base = [...]      # Base features for creating interactions
        self.k = 250.0

    def create_features(self, df):
        """1 row에서 계산 가능한 interaction features 생성"""
        # df = 1 row일 때도 작동
        features = {}

        # Multiplication, Division, Polynomial
        # ... (1 row에서 모두 계산 가능)

        return pd.DataFrame(features)

    def predict(self, test_batch):
        # 1. Extract 1 row
        df = test_batch  # 1 row

        # 2. Create features from this 1 row
        X_all = self.create_features(df)

        # 3. Select Top 30
        X = X_all[self.top_30_features]

        # 4. Predict
        X_scaled = self.scaler.transform(X)
        excess_return = self.model.predict(X_scaled)

        # 5. Convert to position
        position = np.clip(1.0 + excess_return * self.k, 0.0, 2.0)

        return float(position[0])
```

**주요 특징**:
- ✅ 1 row에서 모든 features 계산 가능
- ✅ InferenceServer 호환
- ✅ 실시간 예측 가능

---

### 5. Kaggle 제출 및 결과

#### 제출 정보
- **Version**: 15
- **Date**: 2025-10-21
- **Status**: SubmissionStatus.COMPLETE

#### 결과
- **Public Score**: **4.440**
- **Previous Best** (Version 9): 0.724
- **Improvement**: **6.1배 향상** 🎉

#### 성능 비교
```
Version  | Public Score | Note
---------|--------------|---------------------
9        | 0.724        | 이전 최고
10-13    | ERROR        | lag/rolling features
15       | 4.440        | EXP-016 v2 (최고 기록!)
```

---

## 핵심 인사이트

### 1. 제약 조건이 설계를 결정한다

**InferenceServer = row-by-row 예측**
- 이 제약을 초기에 이해했어야 함
- 제약을 무시한 모든 시도는 실패

**교훈**:
- 프로덕션 환경 제약 조건 먼저 파악
- 실험 전에 deployment 요구사항 확인
- "로컬에서 잘 되는데?"는 의미 없음

### 2. Interaction Features의 놀라운 효과

**예상**:
- CV Sharpe 0.559 (보통 수준)
- 큰 기대 없이 제출

**현실**:
- Public Score 4.440 (6.1배 향상!)
- Interaction features가 test set에서 매우 잘 일반화

**왜 효과적인가?**:
1. **비선형 관계 포착**:
   - `M4*V7`: Market과 Volatility의 상호작용
   - `P8/P7`: 가격 비율 (상대적 변화)
   - `M4²`: 비선형 패턴

2. **도메인 의미**:
   - `P8*S2`: Price momentum × Sentiment
   - `M4/S2`: Market strength / Sentiment
   - `V7*P7`: Volatility × Price (리스크 조정)

3. **Feature Selection 효과**:
   - 120개 생성 → Top 30만 선택
   - XGBoost importance로 정보력 높은 것만 사용
   - 노이즈 제거

### 3. 완전 재설계의 용기

**상황**:
- 기존 EXP-016: 많은 시간 투자
- CV Sharpe 1.001 (3-fold) 달성
- 하지만 제출 불가능

**결단**:
> "016 실험 전체를 처음부터 다시 설계해서 진행해줘. 기존 내용은 모두 삭제하고,"

**결과**:
- ✅ 완전히 새로운 접근 (interaction features)
- ✅ InferenceServer 호환
- ✅ Public Score 4.440 달성

**교훈**:
- Sunk cost fallacy 경계
- 근본 문제 발견 시 과감히 pivot
- "처음부터 다시"가 때로는 더 빠름

### 4. CV Score vs Public Score 괴리

**CV Sharpe**: 0.559 (보통)
**Public Score**: 4.440 (매우 좋음)

**가능한 이유**:
1. **Sharpe vs Public Score metric 차이**:
   - CV: Sharpe ratio (risk-adjusted)
   - Public: Kaggle utility (profit 포함)

2. **Test set 특성**:
   - Interaction features가 test에서 더 잘 작동
   - 시장 regime 변화에 robust

3. **K=250 최적화**:
   - CV에서는 Sharpe 기준으로 최적화
   - Public에서는 다른 metric으로 평가

**시사점**:
- CV score만 믿지 말 것
- 실제 제출해봐야 알 수 있음
- Metric 차이 항상 고려

### 5. Feature Engineering의 올바른 방향

**EXP-007**: 520개 features 추가 → Sharpe +12.6%
- Lag features (60일)
- Rolling statistics
- Cross-sectional features
- Volatility features
- Momentum & Trend

**EXP-016 v2**: 120개 interaction features → Public Score 6.1배
- Multiplication
- Division
- Polynomial
- **1-row calculable**
- **InferenceServer compatible**

**교훈**:
- 많은 features ≠ 좋은 성능
- 제약 조건 내에서 창의적 접근
- 도메인 의미 있는 interaction 선택
- Quality > Quantity

---

## 시도한 것들

### ✅ 성공
1. **문제 인식**: InferenceServer 제약 이해
2. **완전 재설계**: 처음부터 다시 시작
3. **Phase 1**: 원본 features Top 20 선택
4. **Phase 2**: Interaction features 120개 생성 → Top 30 선택
5. **Phase 3**: K parameter 최적화 (K=250)
6. **InferenceServer**: Row-by-row 예측 구현
7. **Kaggle 제출**: Public Score 4.440 달성

### ❌ 실패 (배움)
1. **Version 10-13**: lag/rolling features로 ERROR
2. **초기 설계**: InferenceServer 제약 미고려
3. **K=600 시도**: Position이 극단값 (0 or 2)

---

## 달성한 것

### 정량적 성과
- ✅ **Public Score: 4.440** (최고 기록!)
- ✅ Previous Best (0.724) 대비 **6.1배 향상**
- ✅ CV Sharpe: 0.559 (5-fold)
- ✅ Features: Top 30 (original 20 + interaction 10)

### 정성적 성과
- ✅ **InferenceServer 제약 이해**
  - Row-by-row 예측 메커니즘
  - 1-row calculable features 설계

- ✅ **Interaction Features 효과 입증**
  - 비선형 관계 포착
  - 도메인 의미 있는 feature 생성
  - Feature selection 중요성

- ✅ **체계적 3단계 실험**
  - Phase 1: Base feature selection
  - Phase 2: Feature engineering + selection
  - Phase 3: Model optimization

- ✅ **완전 재설계 경험**
  - Sunk cost 극복
  - 빠른 pivot 실행
  - 근본 문제 해결

---

## 기술적 자산

### 코드
```
experiments/016/
├── README.md                      # 실험 요약 및 결과
├── phase1_analyze_features.py     # 원본 features 분석
├── phase2_feature_engineering.py  # Interaction features 생성
├── phase3_sharpe_evaluation.py    # Sharpe 평가 및 K 최적화
└── results/
    ├── feature_ranking.csv
    ├── top_20_features.csv
    ├── top_30_with_interactions.csv
    ├── final_cv_results.csv
    └── final_config.csv

submissions/
└── submission.py                  # InferenceServer 구현
```

### 재사용 가능한 패턴
1. **Interaction Features 생성**:
   ```python
   # Multiplication, Division, Polynomial
   # 1-row calculable
   ```

2. **InferenceServer Template**:
   ```python
   class MyServer(InferenceServer):
       def create_features(self, df):  # 1-row 작동
       def predict(self, test_batch):  # Row-by-row
   ```

3. **K Parameter Optimization**:
   ```python
   def calculate_sharpe(y_pred, fwd_returns, risk_free, k):
       positions = np.clip(1.0 + y_pred * k, 0.0, 2.0)
       # ...
   ```

---

## 개인 성찰

### 잘한 점
1. ✅ **문제의 근본 원인 파악**:
   - InferenceServer 제약 발견
   - lag/rolling features 불가능 이해

2. ✅ **완전 재설계 결단**:
   - Sunk cost 극복
   - 처음부터 다시 설계
   - 빠른 실행 (3 phases)

3. ✅ **체계적 실험**:
   - Phase별 명확한 목표
   - 결과 문서화
   - 코드 재사용 가능

4. ✅ **창의적 해결책**:
   - Interaction features 활용
   - Feature selection 전략
   - K parameter 최적화

### 개선 필요
1. ❌ **초기 제약 조건 파악 부족**:
   - InferenceServer 요구사항 먼저 확인했어야
   - 10~13번의 실패 제출 방지 가능

2. ❌ **사용자 피드백 늦게 반영**:
   - "feature engineering" 제안을 더 빨리 이해
   - 완전 재설계를 더 빨리 결정

3. ❌ **CV vs Public Score 이해 부족**:
   - CV 0.559 보고 기대 낮춤
   - 실제로는 Public 4.440 달성

### 배운 점
1. **제약 조건 > 모델 성능**:
   - InferenceServer 호환이 첫 번째 조건
   - 성능은 그 다음 문제

2. **Interaction Features의 힘**:
   - 비선형 관계 포착
   - 도메인 지식 반영
   - 적절한 selection 필수

3. **완전 재설계의 가치**:
   - 근본 문제 발견 시 과감히 pivot
   - 처음부터 다시가 때로는 더 빠름
   - Sunk cost fallacy 경계

4. **CV Score의 한계**:
   - CV와 Public metric 다름
   - 실제 제출해봐야 알 수 있음
   - 낮은 CV도 좋은 Public 가능

5. **체계적 접근의 중요성**:
   - 3단계 실험 설계
   - 명확한 목표 설정
   - 결과 문서화

---

## 다음 단계

### Option 1: 현재 모델 개선 (추천 ⭐⭐⭐)
- Interaction features 추가 탐색
- Ensemble (여러 K 값)
- Hyperparameter fine-tuning
- 예상: Public Score 5~7

### Option 2: 새로운 실험
- Deep Learning (LSTM, Transformer)
- Classification approach
- Portfolio optimization
- 리스크: 높음, InferenceServer 제약 여전

### Option 3: 현재 최선 유지 (추천 ⭐⭐⭐⭐⭐)
- Public Score 4.440 충분히 좋음
- 다른 실험으로 이동
- 대회 종료 후 Top Solution 분석

---

## 최종 결론

### 성과
**Public Score 4.440** (6.1배 향상!)
- Version 9 (0.724) → Version 15 (4.440)
- EXP-016 v2 완전 재설계 성공
- InferenceServer 호환 달성

### 핵심 성공 요인
1. **InferenceServer 제약 이해**: Row-by-row 예측
2. **Interaction Features**: 비선형 관계 포착
3. **Feature Selection**: 120개 → Top 30
4. **K=250 최적화**: Position sizing
5. **완전 재설계 결단**: 근본 문제 해결

### 배운 교훈
1. 제약 조건 먼저 파악
2. Interaction features의 힘
3. 완전 재설계의 용기
4. CV ≠ Public Score
5. 체계적 실험 설계

### 마무리
오늘은 **돌파구를 찾은 날**이었습니다.

실패한 Version 10~13을 거쳐, 문제의 근본 원인을 발견했습니다:
- InferenceServer는 row-by-row 예측
- lag/rolling features 사용 불가
- 1-row calculable features만 가능

그리고 완전히 새로운 접근을 시도했습니다:
- 처음부터 재설계 (기존 내용 삭제)
- Interaction features 활용
- 체계적 3단계 실험

결과:
- ✅ Public Score 4.440 (최고 기록!)
- ✅ 6.1배 성능 향상
- ✅ InferenceServer 호환

**"때로는 처음부터 다시 시작하는 것이 가장 빠른 길이다."**

---

**작성일**: 2025-10-21
**작성자**: Claude (AI Assistant)
**실험**: EXP-016 v2 (InferenceServer-Compatible)
**상태**: 완료 ✅, Public Score 4.440 달성
**다음 작업**: 선택적 개선 또는 다음 실험 진행
