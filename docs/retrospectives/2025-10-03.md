# 일일 회고 - 2025-10-03

## 📊 오늘의 주요 성과

### 1. EXP-004 실패 근본 원인 분석

**문제 발견**:
- k=500 제출: CV Sharpe 0.836 (최고) → Kaggle 0.150 (최악)
- k=50 대비 66% 성능 저하
- 예상과 정반대 결과

**근본 원인 파악**:
1. **분포 이동 (Distribution Shift)**
   - 훈련 데이터(2020~2023) vs 테스트 데이터(2024+) 환경 차이
   - k=500이 과거 패턴에 과적합
   - 테스트 데이터에서 예측력 급락

2. **모델 자체의 예측력 부족**
   - Lasso의 excess return 예측 상관계수: 0.03~0.06 (매우 약함)
   - k 파라미터는 증폭기일 뿐: 약한 신호 × 500 = 큰 노이즈
   - 선형 모델의 한계: Feature interaction 포착 불가, 비선형 관계 무시

3. **k 조정의 한계 명확**
   - 현재 점수 0.44 vs 상위권 17.333 → **38~115배 차이**
   - k 값만 조정해서는 이 차이를 절대 메울 수 없음
   - **모델 자체를 바꿔야 함**

**산출물**:
- `experiments/004/SUBMISSION_ANALYSIS.md`: 실패 원인, 시나리오별 대응, 교훈

---

### 2. 전략 전환 결정 (Critical Decision)

**사용자 질문**:
> "전체 구조를 그대로 둔 채 k 값 조정하는 접근으로 17점 이상의 점수를 기대할 수 있는 거야? 아예 접근 방법을 바꾸어야 하는 거 아냐?"

**답변**: **100% 맞습니다. 근본적 접근 변경 필요.**

**현재 접근의 한계**:
```
Lasso + Top-20 features + k tuning
→ CV Sharpe 0.836 (최고)
→ Kaggle 0.15~0.44 (목표 17의 3% 수준)
→ 선형 모델로는 한계 명확
```

**새 접근 방향**:
```
XGBoost/LightGBM + All 98 features + Feature Engineering
→ 비선형 모델
→ Feature interaction 자동 학습
→ 예측력 근본적 향상
→ 상위권 표준 접근법
```

---

### 3. EXP-005 기획 및 준비 완료

**핵심 전략**:
- Lasso (선형) → XGBoost/LightGBM (비선형)
- Top-20 features → 전체 98 features + engineered features
- 단순 correlation → Feature interaction learning

**실험 계획 (6개 가설)**:

| 실험 | 모델 | 특징 | 예상 Sharpe | 우선순위 |
|------|------|------|------------|---------|
| **H1** | XGBoost | Baseline (98 features) | 0.7~0.9 | ⭐⭐⭐⭐⭐ |
| **H2** | LightGBM | Baseline 비교 | 0.7~0.9 | ⭐⭐⭐⭐ |
| **H3** | XGBoost | + Lag/Rolling features | 0.75~0.95 | ⭐⭐⭐⭐⭐ |
| **H4** | XGBoost | + Interaction features | 0.8~1.0 | ⭐⭐⭐⭐ |
| **H5** | Ensemble | XGB+LGBM+Lasso | 0.8~1.0 | ⭐⭐⭐ |
| **H6** | XGBoost | Regime-based | 0.85~1.05 | ⭐⭐⭐ |

**Feature Engineering**:
```python
# Lag features (시계열 패턴)
M4_lag1, M4_lag5, M4_lag10

# Rolling statistics (추세/변동성)
M4_rolling_mean_5, M4_rolling_std_10

# Interaction features (feature 간 관계)
M4_x_V13, M1_x_S5

# Regime indicators (시장 환경)
high_vol, low_vol (V13 기준)
```

**성공 기준**:
- **Minimum**: CV Sharpe > 0.7 (+15% vs Lasso 0.604), Kaggle > 1.0
- **Target**: CV Sharpe > 0.85 (+40%), Kaggle > 3.0 (7배)
- **Stretch**: CV Sharpe > 1.0 (+65%), Kaggle > 5.0, 상위 50%

**산출물**:
- `experiments/005/STRATEGY_PIVOT.md`: 왜 전환이 필요한가, 새 접근 5가지 옵션
- `experiments/005/HYPOTHESES.md`: 6개 가설 상세 명세 (설정, 예상 결과, 성공 기준)
- `experiments/005/README.md`: 실행 가이드, 타임라인, 디버깅 가이드
- `experiments/005/run_experiments.py`: 구현 스켈레톤 (내일 작업용)

---

### 4. 중간 작업: k=200 다운그레이드 (보류)

**배경**: k=500 실패 후 보수적 접근 시도
- k=200으로 다운그레이드
- `kaggle_inference_k200.py`, `simple_submission.py` 업데이트

**결정**: **제출 보류**
- 이유: k 조정으로는 근본적 개선 불가능
- 대신 EXP-005 (XGBoost) 완료 후 제출하는 것이 효율적
- k=200 제출은 시간 낭비 (제출 횟수 제한 고려)

**산출물**:
- `kaggle_kernel/kaggle_inference_k200.py`
- `/tmp/submission_guide_k200.md`

---

## 💡 핵심 인사이트

### 1. "k 파라미터는 증폭기일 뿐"
- **약한 예측 × 500 = 큰 노이즈**
- Lasso 예측 상관 0.03~0.06 수준으로는 k를 아무리 조정해도 한계
- 신호 자체를 강화해야 함 (모델 교체)

### 2. "CV 성능 ≠ Kaggle 성능"
```
k=50:  CV 0.604 → Kaggle 0.441 (73% 유지)
k=500: CV 0.836 → Kaggle 0.150 (18% 유지, 과적합)
```
- 분포 이동에 취약한 모델은 CV가 높아도 실제 성능 낮음
- Hold-out test, Walk-forward validation 필요

### 3. "Kaggle 상위권은 다른 접근 사용"
- 우리: Lasso + Top-20 + k 조정
- 상위권 (추정): XGBoost/LightGBM + Feature Engineering + Ensemble
- **Gap**: 모델 자체가 다름, 파라미터 조정으로는 따라잡을 수 없음

### 4. "Conservative First 전략"
- 첫 제출: 보수적 접근 (k=50~100)
- 테스트 데이터 특성 파악 후 점진적 증가
- 공격적 접근(k=500)을 먼저 시도한 것이 실수

---

## 📝 배운 교훈

### 1. 실험 설계
- ❌ **잘못**: CV 성능만 믿고 k=500 제출
- ✅ **올바름**: Hold-out test로 분포 이동 사전 검증
- ✅ **올바름**: 점진적 접근 (k=50 → k=100 → k=200 → k=500)

### 2. 문제 진단
- ❌ **잘못**: "k 값을 더 조정해보자"
- ✅ **올바름**: "모델 자체의 예측력이 부족하다" (근본 원인)
- 파라미터 튜닝 vs 모델 교체 결정이 중요

### 3. 상위권 분석
- 상위권 17.333 vs 우리 0.44 → 38배 차이
- 이 차이는 k 파라미터만으로는 불가능
- 모델, Feature Engineering, Ensemble 등 근본적 차이

### 4. 제출 전략
- 제출 횟수 제한 (보통 5회/일) 고려
- k=200 제출은 보류하고 XGBoost 완료 후 제출이 효율적
- 실험 우선순위: 큰 변화(모델 교체) > 작은 조정(k 값)

---

## 🎯 의사결정 과정

### 질문 1: "k=200을 제출해야 하나?"
**결정**: **No, 보류**
- k 조정으로는 17+ 불가능
- 제출 횟수 낭비
- XGBoost 완료 후 제출이 더 효율적

### 질문 2: "접근 방법을 바꿔야 하나?"
**결정**: **Yes, 전략 전환 필요**
- Lasso → XGBoost/LightGBM
- k 조정 → Feature Engineering
- 근본적 예측력 향상 필요

### 질문 3: "어떤 실험을 우선 실행?"
**결정**: **H1 (XGBoost) + H3 (Feature Engineering)**
- H1: 기본 성능 확인 (필수)
- H3: 시계열 feature 추가 (효과 클 것으로 예상)
- H2 (LightGBM): 시간 있으면 비교

---

## 📈 진행 현황

### 완료된 작업 ✅
1. ✅ EXP-004 k=500 실패 분석
2. ✅ k=200 다운그레이드 준비 (제출 보류)
3. ✅ 전략 전환 결정 (Lasso → XGBoost)
4. ✅ EXP-005 기획 완료 (6개 가설)
5. ✅ EXP-005 문서화 (HYPOTHESES, README, STRATEGY_PIVOT)
6. ✅ Git 커밋 (6a8eb00, 9c189b9)

### 내일 작업 (Day 1) 📅
**오전 (2~3시간)**:
- [ ] H1: XGBoost Baseline 구현 및 실행
- [ ] H2: LightGBM Baseline 구현 및 실행
- [ ] Feature importance 분석

**오후 (2~3시간)**:
- [ ] H3: Feature Engineering 구현 (Lag, Rolling)
- [ ] H3 실행 및 결과 비교
- [ ] Best model 선정

**저녁 (1~2시간)**:
- [ ] Kaggle 제출 파일 생성 (`kaggle_inference_xgboost.py`)
- [ ] 제출 및 점수 확인
- [ ] 결과 기반 다음 스텝 결정

---

## 📊 메트릭 요약

### EXP-004 최종 결과
| 설정 | CV Sharpe | Kaggle 점수 | Gap |
|------|-----------|------------|-----|
| k=50 (EXP-003) | 0.604 | 0.441 | 73% 유지 |
| k=500 (EXP-004) | 0.836 | 0.150 | 18% 유지 (과적합) ❌ |
| **상위권** | ??? | **17.333** | **목표** |

**Gap to Top**: 38~115배 (k 조정으로는 불가능)

### EXP-005 목표
| 기준 | CV Sharpe | Kaggle 점수 | 개선율 |
|------|-----------|------------|--------|
| Minimum | > 0.7 | > 1.0 | +2배 |
| Target | > 0.85 | > 3.0 | +7배 |
| Stretch | > 1.0 | > 5.0 | +11배 |

---

## 🔍 리스크 및 대응

### Risk 1: XGBoost도 성능 낮음
- **확률**: 30%
- **대응**: Hyperparameter tuning, 더 많은 feature engineering
- **Fallback**: H6 (Regime-based) 또는 Deep Learning 고려

### Risk 2: Overfitting (CV↑ Kaggle↓)
- **확률**: 40% (EXP-004와 동일 패턴)
- **대응**: Hold-out test 도입, Early stopping, Max depth 제한

### Risk 3: 시간 부족
- **확률**: 20%
- **대응**: H1, H3만 필수 실행, H2, H4~H6 선택적

### Risk 4: Feature 폭발 (curse of dimensionality)
- **확률**: 30%
- **대응**: Top-20만 lag/rolling 적용, Feature importance 기반 필터링

---

## 💭 개인적 회고

### 잘한 점
1. **근본 원인 파악**: k 조정의 한계를 명확히 인식
2. **빠른 전략 전환**: 잘못된 방향에 매몰되지 않고 pivot 결정
3. **체계적 기획**: EXP-005 가설, 실행 계획, 성공 기준 명확히 정의
4. **사용자 질문 수용**: "접근을 바꿔야 하는 거 아냐?" → 즉시 동의 및 전환

### 아쉬운 점
1. **k=500 직접 제출**: Hold-out test 없이 CV만 믿고 제출
2. **Conservative First 미준수**: k=50→100→200 순서로 했어야 함
3. **제출 횟수 낭비**: k=200 준비했지만 제출 보류 (시간 낭비)

### 개선할 점
1. **Hold-out test 필수화**: 모든 실험에 최신 20% 데이터 분리 검증
2. **점진적 접근**: 보수적 → 공격적 순서 엄수
3. **실험 우선순위**: 큰 변화(모델 교체) > 작은 조정(파라미터)

---

## 📚 참고 자료

### 생성된 문서
1. `experiments/004/SUBMISSION_ANALYSIS.md`: k=500 실패 분석
2. `experiments/005/STRATEGY_PIVOT.md`: 전략 전환 배경 및 5가지 옵션
3. `experiments/005/HYPOTHESES.md`: 6개 가설 상세 명세
4. `experiments/005/README.md`: 실행 가이드, 타임라인

### Git Commits
1. `6a8eb00`: k=500→k=200 다운그레이드 (제출 보류)
2. `9c189b9`: EXP-005 준비 완료 (전략 전환)

### 기존 실험 참고
- EXP-000: Feature 분석 (Top-20 선정 근거)
- EXP-002: Lasso baseline (Sharpe 0.604)
- EXP-003: 후보 패키징 (Kaggle 0.441)
- EXP-004: k 조정 실험 (실패, Kaggle 0.150)
- **EXP-005: 모델 전환** (XGBoost, 내일 실행)

---

## 🎯 핵심 메시지

**"k 파라미터 조정이 아닌, 모델 자체를 바꿔야 17+ 달성 가능"**

- Lasso (선형, 상관 0.03~0.06) → XGBoost (비선형, interaction 학습)
- Top-20 features → 전체 98 features + Lag + Rolling + Interaction
- k 증폭 → Feature Engineering으로 신호 자체를 강화

**내일의 목표**: H1, H3 실행 → CV Sharpe 0.7+ 달성 → Kaggle 제출

---

**작성일**: 2025-10-03
**소요 시간**: 약 6시간
**상태**: 전략 전환 완료, 내일 실험 준비 완료
**다음**: EXP-005 실행 (XGBoost + Feature Engineering)
