# EXP-004 제출 결과 분석

## 문제 상황

**제출 결과**:
- **k=50 (EXP-003)**: 점수 0.441
- **k=500 (EXP-004)**: 점수 0.150 ❌ (66% 감소)

**예측값 비교**:
```
k=50:  Mean=0.9983, Std=0.0118, Range=[0.9798, 1.0232]
k=500: Mean=0.9834, Std=0.1183, Range=[0.7981, 1.2322]
```

**CV 성능 (로컬)**:
- k=50:  Sharpe 0.604
- k=500: Sharpe 0.836 (+38%)

## 근본 원인 분석

### 1. CV vs Test 데이터 분포 불일치 (가장 유력)

**가설**: 테스트 데이터의 시장 환경이 훈련 데이터와 크게 다름

**증거**:
- CV에서는 k=500이 k=50보다 38% 우수
- 실제 제출에서는 정반대 (k=500이 66% 나쁨)
- 이는 전형적인 **과적합(overfitting)** 또는 **분포 이동(distribution shift)** 신호

**분석**:
```
CV (TimeSeriesSplit):
- 훈련: 2020~2023 데이터
- 검증: 2023~2024 데이터 (최근)
→ k=500이 잘 작동 (변동성 패턴이 일관)

Kaggle Test:
- 테스트: 2024+ 미래 데이터 (예상)
→ k=500 실패 (변동성/시장 환경 변화)
```

**해석**:
- k=500은 **과거 데이터 패턴에 과도하게 최적화**됨
- 테스트 기간에는 시장 변동성이 다르거나 예측 신호가 약해짐
- 공격적 포지션(k=500)이 오히려 노이즈를 증폭

### 2. Modified Sharpe Ratio 평가 방식 차이

**가설**: Kaggle의 Modified Sharpe는 로컬 Sharpe와 다른 계산법 사용

**Kaggle 평가 (추정)**:
```python
# 예상 평가 공식 (정확한 공식은 비공개)
modified_sharpe = (mean_excess / std_excess) * sqrt(252)
# 하지만 추가 페널티가 있을 수 있음:
# - 극단 포지션 페널티 (0 또는 2에 가까운 값)
# - 변동성 페널티 (vol_ratio > 1.2)
# - 턴오버 페널티 (포지션 변화가 클 때)
```

**k=500의 문제**:
- 포지션 범위: [0.798, 1.232] (매우 넓음)
- 극단값 비중: 0.8 이하, 1.2 이상 빈번
- → Kaggle이 극단 포지션에 페널티를 부과할 가능성

### 3. 테스트 데이터의 낮은 예측력

**가설**: 모델의 excess return 예측이 테스트 데이터에서 정확도가 낮음

**분석**:
```
k=50 (보수적):
- 예측 오차가 있어도 포지션 변화 작음 (±2%)
- 거의 시장 수익률 추종 (안전)
→ 오차 영향 최소화

k=500 (공격적):
- 예측 오차를 10배 증폭 (±20%)
- 잘못된 예측이 큰 손실로 이어짐
→ 오차 영향 극대화
```

**결론**: 테스트 데이터에서 모델 예측력이 떨어지면, k 값이 클수록 성능 저하가 심함

### 4. 시장 환경 변화 (Regime Change)

**가능성**: 테스트 기간에 시장 체제 전환 발생

**예시**:
- 훈련: 저금리, 고성장 환경 (2020~2023)
- 테스트: 고금리, 저성장 또는 침체 (2024+)
- → 과거에 학습한 excess return 패턴이 무효화

**k=500의 취약성**:
- 훈련 데이터 패턴에 강하게 의존
- 새로운 시장 환경에서 적응 실패
- k=50은 보수적이라 환경 변화에 덜 민감

## 실험 검증 방안

### Option 1: Out-of-Sample Test (권장)

**목적**: 로컬에서 분포 이동 시뮬레이션

```python
# 훈련: 2020~2022
# CV: 2023
# Hold-out test: 2024
# → 가장 오래된 데이터로 훈련, 가장 최신 데이터로 테스트
```

**실행**:
```bash
# 최신 데이터만 hold-out 테스트
uv run python experiments/004/verify_distribution_shift.py
```

### Option 2: Conservative k Grid Search

**가설**: k=50~200 범위에서 최적값 재탐색

**테스트 범위**:
- k=50 (현재 0.441, baseline)
- k=75
- k=100
- k=150
- k=200

**예상**: k=100~150에서 CV와 Test 성능 균형 찾기

### Option 3: Prediction Confidence Filtering

**아이디어**: 낮은 확신도 예측에는 k 값 줄이기

```python
# 예측 확신도에 따라 k 동적 조정
confidence = abs(excess_pred)
if confidence < threshold:
    k_effective = k * 0.3  # 확신 없으면 보수적
else:
    k_effective = k  # 확신 있으면 공격적
```

## 즉시 실행 가능한 액션

### 1. k 값 다운 그레이드 제출 (최우선) ⭐⭐⭐

**k=200 제출** (H3a_large_k200):
- CV Sharpe: 0.788 (k=50 대비 +30%)
- 안정성: Sharpe Std 0.159 (k=500 대비 2배 안정)
- 포지션 범위: 더 보수적, 극단값 적음
- **예상 점수**: 0.5~1.5 (k=50보다 나을 가능성 높음)

**k=150 제출** (신규):
- k=200과 k=100 중간값
- CV 재테스트 필요 없음 (바로 제출 가능)
- **예상 점수**: 0.6~2.0

**k=100 제출**:
- k=50과 k=200 중간
- **예상 점수**: 0.5~1.2

### 2. H2a 예측 스케일 조정 + k=50 제출 (안정성 우선) ⭐⭐⭐⭐

**설정**: Prediction Scaling + k=50
- CV Sharpe: 0.821 (3위)
- **CV 안정성**: Sharpe Std 0.210 (전체 1위)
- 포지션: 보수적, 극단값 회피
- **예상 점수**: 0.8~3.0 (안정적 개선 기대)

**장점**:
- k=50 유지하면서 예측 품질 개선
- 분포 이동에 덜 민감
- 극단 포지션 페널티 회피

### 3. 앙상블: k=50 70% + k=200 30% (절충) ⭐⭐⭐

**아이디어**: 보수적(k=50)과 공격적(k=200) 혼합

```python
pos_conservative = clip(1.0 + excess * 50, 0, 2)
pos_aggressive = clip(1.0 + excess * 200, 0, 2)
final_pos = 0.7 * pos_conservative + 0.3 * pos_aggressive
```

**예상**:
- k=50 안정성 유지
- k=200 상승 가능성 일부 확보
- **예상 점수**: 0.6~2.0

## 추천 제출 순서

### Phase 1: 보수적 재검증 (1~3일)

1. **k=200 제출** → 점수 확인
   - 점수 > 0.6: Phase 2로 진행
   - 점수 < 0.45: k 값 추가 다운 (k=100)

2. **H2a_pred_scaling_k50 제출** → 점수 확인
   - 안정성 테스트

3. **k=150 제출** (k=100~200 범위 좁히기)

### Phase 2: 원인 파악 (병렬)

4. 로컬에서 **Out-of-Sample 테스트** 실행
   - 가장 오래된 데이터로 훈련
   - 가장 최신 데이터로 검증
   - k별 성능 비교

5. 실제 제출 결과와 비교
   - 분포 이동 패턴 파악
   - k 최적값 재추정

### Phase 3: 최적화 (결과 기반)

6. Phase 1~2 결과로 최종 k 값 결정
7. Confidence-weighted k 또는 앙상블 고려

## 교훈 및 개선점

### 1. CV 검증 방식 개선 필요

**현재 문제**:
- TimeSeriesSplit이 훈련 데이터 내에서만 검증
- 미래 데이터(테스트)와 환경이 다를 가능성 미고려

**개선안**:
- **Hold-out test**: 최신 6개월 데이터 완전 분리
- **Walk-forward validation**: 롤링 윈도우 검증
- **Adverse scenario test**: 변동성 큰 기간만 별도 검증

### 2. Robustness 메트릭 추가

**현재**: Sharpe, Vol Ratio만 사용
**추가 필요**:
- **Maximum Drawdown**: 최대 손실 제한
- **Sharpe 최악 케이스**: 5-fold 중 최저 Sharpe
- **Position Extremeness**: 극단 포지션(0~0.3, 1.7~2.0) 비중
- **Turnover**: 포지션 변화율

### 3. Conservative First 전략

**교훈**: 처음 제출은 항상 보수적으로
- 첫 제출: k=50~100 (안정성 검증)
- 두 번째: k=150~200 (점진적 증가)
- 최종: k=300~500 (공격적 시도)

**이유**:
- 테스트 데이터 특성 파악
- 제출 횟수 제한 (보통 5회/일)
- 리스크 최소화

## 요약

### 핵심 원인 (추정)
1. **분포 이동**: 테스트 데이터가 훈련 데이터와 시장 환경이 다름
2. **과적합**: k=500이 CV 데이터 패턴에 과도하게 최적화
3. **낮은 예측력**: 테스트 기간에 모델 예측 정확도 하락
4. **극단 포지션 페널티**: Kaggle이 [0.8, 1.2] 범위 벗어난 포지션에 불이익

### 즉시 조치
1. ✅ **k=200 제출** (H3a_large_k200, CV Sharpe 0.788)
2. ✅ **H2a_pred_scaling_k50 제출** (CV Sharpe 0.821, 최고 안정성)
3. ⏭️ Out-of-Sample 검증 (로컬)

### 중기 전략
- k 값 범위를 50~200으로 제한
- 안정성 메트릭 강화
- Hold-out test 도입

---

**작성일**: 2025-10-03
**실험**: EXP-004
**상태**: k=500 실패 분석 완료, 재제출 대기
