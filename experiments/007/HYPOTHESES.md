# EXP-007 ê°€ì„¤ ë° ì‹¤í—˜ ê³„íš: ì˜ˆì¸¡ ì •í™•ë„ ê·¼ë³¸ ê°œì„ 

## ë°°ê²½

### EXP-006 ì‹¤íŒ¨ ë¶„ì„
- **ì‹œë„**: k íŒŒë¼ë¯¸í„° ì¦ê°€ (200â†’3000, 15ë°°)
- **ê²°ê³¼**: Sharpe 0.627â†’0.699 (+11.4%, 1.11ë°°)
- **ì‹¤íŒ¨ ì›ì¸**: ì˜ˆì¸¡ ì •í™•ë„ ìì²´ê°€ ë„ˆë¬´ ë‚®ìŒ
  - MSE: 0.00015
  - Correlation: 0.03~0.06
  - këŠ” ì‹ í˜¸ ì¦í­ë§Œ ê°€ëŠ¥, ì‹ í˜¸ ìƒì„± ë¶ˆê°€

### Kaggle ë©”íŠ¸ë¦­ ì¬ì´í•´
```
utility = min(max(sharpe, 0), 6) Ã— Î£ profits
```

**í•µì‹¬ í†µì°°**:
1. SharpeëŠ” [0, 6]ìœ¼ë¡œ í´ë¨í•‘
2. Sharpe 6 ì´ìƒì€ ì˜ë¯¸ ì—†ìŒ
3. **Profitì´ í•µì‹¬ ë³€ìˆ˜**
4. ëª©í‘œ 17.395 = sharpe(6) Ã— profit(~2.9)

**í˜„ì¬ ìƒí™©**:
- Sharpe: 0.699 (best k=3000)
- ëª©í‘œ: 6.0
- ê²©ì°¨: 8.6ë°°

---

## ëª©í‘œ

### Primary Goal
**Sharpe 1.5~3.0 ë‹¬ì„±** (í˜„ì¬ 0.7 ëŒ€ë¹„ 2~4ë°°)

### Milestone
- Milestone 1: Sharpe 1.0+ (í˜„ì¬ ëŒ€ë¹„ 1.4ë°°)
- Milestone 2: Sharpe 1.5+ (2.1ë°°)
- Milestone 3: Sharpe 2.0+ (2.9ë°°)
- Stretch: Sharpe 3.0+ (4.3ë°°)

### Success Criteria
- **Minimum**: Sharpe 1.0+ (CV), Kaggle utility 3.0+
- **Target**: Sharpe 1.5+ (CV), Kaggle utility 6.0+
- **Stretch**: Sharpe 2.0+ (CV), Kaggle utility 10.0+

---

## ê°€ì„¤ (ìš°ì„ ìˆœìœ„ë³„)

### ğŸ¥‡ H1: Feature Engineering í™•ì¥
**ê°€ì„¤**: ë” ê¸´ ì‹œê³„ì—´ + ë‹¤ì–‘í•œ featuresë¡œ ì˜ˆì¸¡ë ¥ í–¥ìƒ

**ë°°ê²½**:
- í˜„ì¬ Lag [1, 5, 10]: ë„ˆë¬´ ì§§ìŒ (2ì£¼ ì´ë‚´)
- ì‹œì¥ ì‚¬ì´í´ì€ 20~60ì¼ ê°€ëŠ¥ì„±
- Cross-sectional features ì—†ìŒ (date ë‚´ ìƒëŒ€ ë¹„êµ)
- Volatility features ì—†ìŒ

**ì‹¤í—˜ ë‚´ìš©**:
- **H1a: Longer Lags**
  - Lag [1, 5, 10, 20, 40, 60]
  - ì˜ˆìƒ: ì¤‘ì¥ê¸° íŒ¨í„´ í¬ì°©, Sharpe +10~20%

- **H1b: Cross-Sectional Features**
  - Rank within date: featureë³„ ìˆœìœ„ (0~1 normalize)
  - Quantile: featureë³„ ë¶„ìœ„ìˆ˜ (0.2, 0.4, 0.6, 0.8)
  - Z-score: (value - date_mean) / date_std
  - ì˜ˆìƒ: ìƒëŒ€ì  ê°•ë„ í¬ì°©, Sharpe +15~30%

- **H1c: Volatility Features**
  - Rolling vol [5, 20, 60]
  - Volatility regime: ê³ ë³€ë™ vs ì €ë³€ë™
  - Vol-normalized returns
  - ì˜ˆìƒ: ë³€ë™ì„± ê³ ë ¤, Sharpe +10~25%

- **H1d: Momentum & Trend**
  - Return [5d, 20d, 60d]
  - EMA [10, 20, 40, 60]
  - MACD-like features
  - ì˜ˆìƒ: íŠ¸ë Œë“œ í¬ì°©, Sharpe +5~15%

**ì¸¡ì • ì§€í‘œ**:
- CV Sharpe (primary)
- Feature importance (top 20)
- Train vs CV ì°¨ì´ (ê³¼ì í•© ì²´í¬)
- Position distribution

**ì˜ˆìƒ ê²°ê³¼**:
- Best case: Sharpe 1.2~1.5 (+71~114%)
- Realistic: Sharpe 0.9~1.1 (+29~57%)
- Worst case: Sharpe 0.75~0.85 (+7~21%)

**ë¦¬ìŠ¤í¬**:
- ê³¼ì í•©: feature ìˆ˜ ì¦ê°€ â†’ overfitting
- ì—°ì‚° ì‹œê°„: feature engineering ëŠë ¤ì§
- Cold start: lag featuresì˜ ì´ˆê¸° NaN

**ì„±ê³µ ê¸°ì¤€**:
- CV Sharpe > 1.0
- Feature importanceì— ìƒˆ features ì§„ì…
- CV-Train Sharpe ì°¨ì´ < 0.15 (ê³¼ì í•© ë°©ì§€)

---

### ğŸ¥ˆ H2: Volatility Scaling
**ê°€ì„¤**: Vol-aware positioningìœ¼ë¡œ ë³€ë™ì„± ë†’ì€ êµ¬ê°„ì—ì„œ ì†ì‹¤ ê°ì†Œ

**ë°°ê²½**:
- í˜„ì¬ `position = 1 + excess * k` (volatility ë¬´ì‹œ)
- Vol Ratio: 1.23~1.46 (ì‹œì¥ ë³€ë™ì„± ëŒ€ë¹„ ë†’ìŒ)
- ê³ ë³€ë™ì„± êµ¬ê°„ì—ì„œ ê³¼ë„í•œ position â†’ ì†ì‹¤ ì¦í­

**ì‹¤í—˜ ë‚´ìš©**:
- **H2a: Simple Vol Scaling**
  ```python
  position = 1 + (excess * k) / rolling_vol_20
  ```
  - ê³ ë³€ë™ì„± ì‹œ position ê°ì†Œ
  - ì˜ˆìƒ: Sharpe +10~15%, Vol Ratio ê°ì†Œ

- **H2b: Vol Targeting**
  ```python
  target_vol = 0.01  # daily
  position = (1 + excess * k) * (target_vol / realized_vol)
  ```
  - ì¼ì • ë³€ë™ì„± ìœ ì§€
  - ì˜ˆìƒ: Sharpe +15~25%, Vol Ratio â†’ 1.0

- **H2c: Dynamic k by Vol Regime**
  ```python
  if rolling_vol > high_threshold:
      k_adjusted = k * 0.5
  elif rolling_vol < low_threshold:
      k_adjusted = k * 1.5
  else:
      k_adjusted = k
  ```
  - ê³ ë³€ë™ì„±: ë³´ìˆ˜ì  (kâ†“)
  - ì €ë³€ë™ì„±: ê³µê²©ì  (kâ†‘)
  - ì˜ˆìƒ: Sharpe +20~30%

**ì¸¡ì • ì§€í‘œ**:
- CV Sharpe
- Vol Ratio (ëª©í‘œ: < 1.2)
- Max position, Pos std

**ì˜ˆìƒ ê²°ê³¼**:
- Best case: Sharpe 1.0~1.2 (+43~71%)
- Realistic: Sharpe 0.85~0.95 (+21~36%)

**ì„±ê³µ ê¸°ì¤€**:
- CV Sharpe > 0.85
- Vol Ratio < 1.2
- vs H1: ë…ë¦½ì  íš¨ê³¼ í™•ì¸ (H1+H2 > H1)

---

### ğŸ¥‰ H3: Ensemble
**ê°€ì„¤**: ì—¬ëŸ¬ ëª¨ë¸ ê²°í•©ìœ¼ë¡œ ì˜ˆì¸¡ ì•ˆì •ì„± í–¥ìƒ

**ë°°ê²½**:
- EXP-005: XGBoost (0.627) vs LightGBM (0.611)
- ê° ëª¨ë¸ì´ ë‹¤ë¥¸ íŒ¨í„´ í¬ì°© ê°€ëŠ¥ì„±
- Ensembleë¡œ ë¶„ì‚° ê°ì†Œ

**ì‹¤í—˜ ë‚´ìš©**:
- **H3a: Simple Average**
  ```python
  pred = (xgb_pred + lgbm_pred + lasso_pred) / 3
  ```
  - ë™ì¼ ê°€ì¤‘ì¹˜
  - ì˜ˆìƒ: Sharpe 0.8~0.9

- **H3b: Weighted Average**
  ```python
  pred = 0.5*xgb_pred + 0.3*lgbm_pred + 0.2*lasso_pred
  ```
  - CV Sharpe ê¸°ë°˜ ê°€ì¤‘ì¹˜
  - ì˜ˆìƒ: Sharpe 0.85~0.95

- **H3c: Stacking**
  - Meta-learner (Linear Regression)
  - Base: XGBoost, LightGBM, Lasso
  - ì˜ˆìƒ: Sharpe 0.9~1.1

**ì¸¡ì • ì§€í‘œ**:
- CV Sharpe
- ê° ëª¨ë¸ë³„ ê¸°ì—¬ë„
- Correlation between models (ë‹¤ì–‘ì„± í™•ì¸)

**ì˜ˆìƒ ê²°ê³¼**:
- Best case: Sharpe 1.0~1.2 (+43~71%)
- Realistic: Sharpe 0.85~0.95 (+21~36%)

**ì„±ê³µ ê¸°ì¤€**:
- CV Sharpe > best single model + 0.05
- Model correlation < 0.9 (ë‹¤ì–‘ì„± í™•ë³´)

---

### H4: Neural Network (ì„ íƒ)
**ê°€ì„¤**: DLë¡œ ë³µì¡í•œ ë¹„ì„ í˜• ê´€ê³„ í¬ì°©

**ë°°ê²½**:
- XGBoost/LightGBM: tree-based, feature interaction ì œí•œì 
- Neural Network: ì„ì˜ ë¹„ì„ í˜• í•¨ìˆ˜ ê·¼ì‚¬

**ì‹¤í—˜ ë‚´ìš©**:
- **H4a: MLP**
  - 3~5 layers, ReLU, Dropout
  - BatchNorm
  - ì˜ˆìƒ: Sharpe 0.9~1.2

- **H4b: LSTM** (ì‹œê³„ì—´)
  - Sequence length: 10~20
  - Bi-directional
  - ì˜ˆìƒ: Sharpe 1.0~1.4

- **H4c: Transformer** (advanced)
  - Attention mechanism
  - ì˜ˆìƒ: Sharpe 1.2~1.8

**ë¦¬ìŠ¤í¬**:
- í›ˆë ¨ ì‹œê°„ ê¸¸ì–´ì§
- ê³¼ì í•© ìœ„í—˜ ë†’ìŒ
- Hyperparameter ë¯¼ê°

**ì¡°ê±´**: H1~H3 ì‹¤íŒ¨ ì‹œ (Sharpe < 1.0)

---

### H5: Target Engineering (Radical, ì„ íƒ)
**ê°€ì„¤**: ë‹¤ë¥¸ target ì •ì˜ë¡œ ì˜ˆì¸¡ ìš©ì´ì„± í–¥ìƒ

**ë°°ê²½**:
- í˜„ì¬ target: market_forward_excess_returns (regression)
- Regressionì€ magnitude ì˜ˆì¸¡ ì–´ë ¤ì›€
- Classification (sign)ì´ ë” ì‰¬ìš¸ ìˆ˜ ìˆìŒ

**ì‹¤í—˜ ë‚´ìš©**:
- **H5a: Classification + Regression**
  1. Classifier: sign(excess) ì˜ˆì¸¡ (binary)
  2. Regressor: |excess| ì˜ˆì¸¡ (magnitude)
  3. Final: sign Ã— magnitude
  - ì˜ˆìƒ: Sharpe 1.0~1.5

- **H5b: Quantile Regression**
  - P10, P50, P90 ì˜ˆì¸¡
  - Tail events ì¤‘ì 
  - ì˜ˆìƒ: Sharpe 1.2~1.8

- **H5c: Multi-task Learning**
  - Task 1: Excess return
  - Task 2: Volatility
  - Task 3: Sign
  - ì˜ˆìƒ: Sharpe 1.3~2.0

**ì¡°ê±´**: H1~H4 ì‹¤íŒ¨ ì‹œ (Sharpe < 1.2)

---

## ì‹¤í—˜ ê³„íš

### Phase 1: Feature Engineering (H1)
**ëª©í‘œ**: Sharpe 1.0+ ë‹¬ì„±

**ìˆœì„œ**:
1. H1a: Longer Lags (30ë¶„)
2. H1b: Cross-Sectional (45ë¶„)
3. H1c: Volatility Features (30ë¶„)
4. H1d: Momentum & Trend (30ë¶„)
5. ì¡°í•© í…ŒìŠ¤íŠ¸: H1a+b+c+d (1ì‹œê°„)

**ì˜ˆìƒ ì‹œê°„**: 3~4ì‹œê°„

**ì˜ì‚¬ê²°ì •**:
```
H1 ê²°ê³¼:
  â”œâ”€ Sharpe > 1.2 âœ… â†’ Phase 2 (H2), ëª©í‘œ ë‹¬ì„± ê·¼ì ‘
  â”œâ”€ Sharpe 1.0~1.2 ğŸ“Š â†’ Phase 2 (H2), ì¶”ê°€ ê°œì„  í•„ìš”
  â”œâ”€ Sharpe 0.85~1.0 ğŸ“‰ â†’ Phase 2 (H2) + Phase 3 (H3) í•„ìˆ˜
  â””â”€ Sharpe < 0.85 âŒ â†’ H4 (Neural Network) ê³ ë ¤
```

---

### Phase 2: Volatility Scaling (H2)
**ì¡°ê±´**: Phase 1 ì™„ë£Œ í›„

**ëª©í‘œ**: Sharpe +0.15~0.25 ì¶”ê°€ ê°œì„ 

**ìˆœì„œ**:
1. H2a: Simple Vol Scaling (30ë¶„)
2. H2b: Vol Targeting (30ë¶„)
3. H2c: Dynamic k (45ë¶„)
4. ìµœê³  ì¡°í•© ì„ ì •

**ì˜ˆìƒ ì‹œê°„**: 2ì‹œê°„

**ì˜ì‚¬ê²°ì •**:
```
H1 + H2 ê²°ê³¼:
  â”œâ”€ Sharpe > 1.5 ğŸ‰ â†’ Kaggle ì œì¶œ, Phase 3 (H3) ì„ íƒ
  â”œâ”€ Sharpe 1.2~1.5 ğŸ“ˆ â†’ Phase 3 (H3) ì§„í–‰
  â”œâ”€ Sharpe 1.0~1.2 ğŸ“Š â†’ Phase 3 (H3) í•„ìˆ˜
  â””â”€ Sharpe < 1.0 âš ï¸ â†’ H4 (Neural Network) í•„ìˆ˜
```

---

### Phase 3: Ensemble (H3)
**ì¡°ê±´**: Phase 2 ì™„ë£Œ í›„ Sharpe < 1.5

**ëª©í‘œ**: Sharpe +0.1~0.2 ì¶”ê°€ ê°œì„ 

**ìˆœì„œ**:
1. H3a: Simple Average (30ë¶„)
2. H3b: Weighted Average (15ë¶„)
3. H3c: Stacking (1ì‹œê°„)

**ì˜ˆìƒ ì‹œê°„**: 2ì‹œê°„

**ì˜ì‚¬ê²°ì •**:
```
H1 + H2 + H3 ê²°ê³¼:
  â”œâ”€ Sharpe > 1.5 ğŸ¯ â†’ Kaggle ì œì¶œ, k ì¬ì¡°ì •
  â”œâ”€ Sharpe 1.2~1.5 ğŸ“Š â†’ Kaggle ì œì¶œ, H4 ê³ ë ¤
  â””â”€ Sharpe < 1.2 âŒ â†’ H4 (Neural Network) í•„ìˆ˜
```

---

### Phase 4: Neural Network (H4) - Conditional
**ì¡°ê±´**: Phase 3 ì™„ë£Œ í›„ Sharpe < 1.5

**ëª©í‘œ**: Sharpe 1.5~2.0 ë‹¬ì„±

**ìˆœì„œ**:
1. H4a: MLP (2ì‹œê°„)
2. H4b: LSTM (3ì‹œê°„)
3. (H4c: TransformerëŠ” ì‹œê°„ ìˆì„ ë•Œë§Œ)

**ì˜ˆìƒ ì‹œê°„**: 5~8ì‹œê°„

---

## ì‹¤í—˜ ì‚°ì¶œë¬¼

### í•„ìˆ˜ íŒŒì¼
```
experiments/007/
â”œâ”€â”€ HYPOTHESES.md           # ì´ íŒŒì¼
â”œâ”€â”€ run_experiments.py      # ì‹¤í—˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ feature_engineering.py  # í™•ì¥ëœ feature ìƒì„±
â”œâ”€â”€ volatility_scaling.py   # Vol scaling ë¡œì§
â”œâ”€â”€ ensemble.py             # Ensemble êµ¬í˜„
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ h1_feature_eng.csv
â”‚   â”œâ”€â”€ h2_vol_scaling.csv
â”‚   â”œâ”€â”€ h3_ensemble.csv
â”‚   â””â”€â”€ summary.csv
â””â”€â”€ REPORT.md               # ì‹¤í—˜ ê²°ê³¼ (ì™„ë£Œ í›„)
```

---

## ë¦¬ìŠ¤í¬ ê´€ë¦¬

### Risk 1: ê³¼ì í•©
**ì¦ìƒ**: CV Sharpe ë†’ì§€ë§Œ Kaggle ë‚®ìŒ
**í™•ë¥ **: 40%
**ëŒ€ì‘**:
- Train vs CV Sharpe ì°¨ì´ ëª¨ë‹ˆí„°ë§
- Early stopping
- Feature ìˆ˜ ì œí•œ

### Risk 2: ê°œì„ í­ ì—¬ì „íˆ ë¶€ì¡±
**ì¦ìƒ**: H1~H3 í›„ì—ë„ Sharpe < 1.0
**í™•ë¥ **: 30%
**ëŒ€ì‘**: H4 (Neural Network) ë˜ëŠ” H5 (Target Engineering)

### Risk 3: ì—°ì‚° ì‹œê°„ í­ë°œ
**ì¦ìƒ**: Feature engineering ë„ˆë¬´ ëŠë¦¼
**í™•ë¥ **: 20%
**ëŒ€ì‘**:
- Feature ìˆ˜ ì œí•œ (top 50~100)
- Sampling

### Risk 4: Cold start ë¬¸ì œ
**ì¦ìƒ**: Lag 60 featuresë¡œ ì¸í•œ ì´ˆê¸° NaN
**í™•ë¥ **: 30%
**ëŒ€ì‘**:
- Forward fill
- Featureë³„ lag ì°¨ë³„í™” (ì¤‘ìš” featureë§Œ lag 60)

---

## ì„±ê³µ ê¸°ì¤€ (Exit Criteria)

### Minimum Success
- âœ… CV Sharpe > 1.0
- âœ… Kaggle utility > 3.0
- âœ… CV-Train Sharpe ì°¨ì´ < 0.2

### Target Success
- âœ… CV Sharpe > 1.5
- âœ… Kaggle utility > 6.0
- âœ… Feature importance ë¶„ì„ ì™„ë£Œ

### Stretch Success
- âœ… CV Sharpe > 2.0
- âœ… Kaggle utility > 10.0
- âœ… 17.395 ë‹¬ì„± ë¡œë“œë§µ ëª…í™•í™”

---

## ë‹¤ìŒ ë‹¨ê³„

1. âœ… HYPOTHESES.md ì‘ì„±
2. â­ï¸ `run_experiments.py` ì‘ì„± (Phase 1: H1)
3. â­ï¸ `feature_engineering.py` ì‘ì„± (í™•ì¥ features)
4. â­ï¸ Phase 1 ì‹¤í–‰ (H1a~d)
5. â­ï¸ ê²°ê³¼ ë¶„ì„ ë° Phase 2 ì§„í–‰ ì—¬ë¶€ ê²°ì •

---

**ì‘ì„±ì¼**: 2025-10-13
**ì „ì œ**: EXP-006 k ì ‘ê·¼ ì‹¤íŒ¨ (Sharpe 0.7 í•œê³„)
**ëª©í‘œ**: ì˜ˆì¸¡ ì •í™•ë„ ê·¼ë³¸ ê°œì„ ìœ¼ë¡œ Sharpe 1.5~3.0 ë‹¬ì„±
**í•µì‹¬**: Feature Engineering + Volatility Scaling + Ensemble
